{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2c5cd7",
   "metadata": {},
   "source": [
    "# Car Brand Recognition Project - Problem Understanding\n",
    "\n",
    "## DAT158 Machine Learning Assignment 3\n",
    "\n",
    "This notebook explores and defines the problem for our car brand recognition machine learning project. We'll analyze the requirements, explore datasets, and set clear objectives for the project.\n",
    "\n",
    "### Project Overview\n",
    "We aim to build a machine learning model that can classify car brands from images using deep learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ea9dd",
   "metadata": {},
   "source": [
    "## 1. Define the Problem Statement\n",
    "\n",
    "Let's clearly define what our model should accomplish and the different approaches we can take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5bb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define problem statement and possible approaches\n",
    "\n",
    "print(\"=== CAR IMAGE CLASSIFICATION PROJECT ===\\n\")\n",
    "\n",
    "# Option 1: Car Brand Recognition\n",
    "print(\"üöó OPTION 1: Car Brand Recognition\")\n",
    "print(\"Input: Image of a car\")\n",
    "print(\"Output: Car brand (BMW, Tesla, Toyota, Mercedes, etc.)\")\n",
    "print(\"Application: Car dealerships, insurance, auto identification\")\n",
    "print(\"Complexity: Medium\")\n",
    "print()\n",
    "\n",
    "# Option 2: Car Type Classification  \n",
    "print(\"üöô OPTION 2: Car Type Classification\")\n",
    "print(\"Input: Image of a car\")\n",
    "print(\"Output: Car type (SUV, Sedan, Truck, Sports Car, etc.)\")\n",
    "print(\"Application: Parking systems, traffic analysis\")\n",
    "print(\"Complexity: Medium\")\n",
    "print()\n",
    "\n",
    "# Option 3: Car Damage Detection\n",
    "print(\"üîß OPTION 3: Car Damage Detection\")\n",
    "print(\"Input: Image of a car\")\n",
    "print(\"Output: Damage status (Damaged/Not Damaged)\")\n",
    "print(\"Application: Insurance claims, used car evaluation\")\n",
    "print(\"Complexity: High\")\n",
    "print()\n",
    "\n",
    "# Our chosen approach\n",
    "print(\"‚úÖ CHOSEN APPROACH: Car Brand Recognition\")\n",
    "print(\"Reasons:\")\n",
    "print(\"- Clear, well-defined classes\")\n",
    "print(\"- Good availability of labeled data\")\n",
    "print(\"- Practical commercial applications\")\n",
    "print(\"- Appropriate complexity for course project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input/output specifications\n",
    "class CarBrandClassificationSpec:\n",
    "    def __init__(self):\n",
    "        self.input_format = \"RGB Image\"\n",
    "        self.input_size = \"224x224 pixels (standard for CNN)\"\n",
    "        self.output_format = \"Class label + confidence score\"\n",
    "        self.target_brands = [\n",
    "            \"Audi\", \"BMW\", \"Ford\", \"Honda\", \n",
    "            \"Mercedes\", \"Nissan\", \"Tesla\", \"Toyota\"\n",
    "        ]\n",
    "        self.num_classes = len(self.target_brands)\n",
    "    \n",
    "    def describe_problem(self):\n",
    "        print(\"=== PROBLEM SPECIFICATION ===\")\n",
    "        print(f\"Input: {self.input_format} ({self.input_size})\")\n",
    "        print(f\"Output: {self.output_format}\")\n",
    "        print(f\"Number of classes: {self.num_classes}\")\n",
    "        print(f\"Target brands: {', '.join(self.target_brands)}\")\n",
    "        print()\n",
    "        print(\"Use Cases:\")\n",
    "        print(\"- Automatic car inventory management\")\n",
    "        print(\"- Insurance claim processing\")\n",
    "        print(\"- Traffic monitoring and analysis\")\n",
    "        print(\"- Car sharing/rental applications\")\n",
    "\n",
    "# Create and display specification\n",
    "spec = CarBrandClassificationSpec()\n",
    "spec.describe_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39cd63",
   "metadata": {},
   "source": [
    "## 2. Explore Available Datasets\n",
    "\n",
    "Let's research and analyze potential datasets for our car brand recognition project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research available datasets for car classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset information\n",
    "datasets_info = {\n",
    "    'Dataset': [\n",
    "        'Stanford Cars Dataset',\n",
    "        'Cars Dataset (Krzysztof)',\n",
    "        'CompCars Dataset',\n",
    "        'VehicleNet',\n",
    "        'Custom Dataset'\n",
    "    ],\n",
    "    'Source': [\n",
    "        'Stanford AI Lab / Kaggle',\n",
    "        'Kaggle',\n",
    "        'MMLAB',\n",
    "        'MIT',\n",
    "        'Self-collected'\n",
    "    ],\n",
    "    'Images': [\n",
    "        '16,185',\n",
    "        '8,144',\n",
    "        '136,726',\n",
    "        '5.6M',\n",
    "        'Variable'\n",
    "    ],\n",
    "    'Classes': [\n",
    "        '196 car models',\n",
    "        '196 car models',\n",
    "        '1,716 car models',\n",
    "        '1,000+ models',\n",
    "        'Custom brands'\n",
    "    ],\n",
    "    'Advantages': [\n",
    "        'Well-labeled, diverse angles',\n",
    "        'Clean, preprocessed data',\n",
    "        'Very comprehensive',\n",
    "        'Huge dataset',\n",
    "        'Tailored to our needs'\n",
    "    ],\n",
    "    'Challenges': [\n",
    "        'Many fine-grained classes',\n",
    "        'Limited size',\n",
    "        'Large download size',\n",
    "        'Very large, complex',\n",
    "        'Need manual labeling'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_datasets = pd.DataFrame(datasets_info)\n",
    "print(\"=== AVAILABLE CAR DATASETS ===\\n\")\n",
    "for idx, row in df_datasets.iterrows():\n",
    "    print(f\"üìä {row['Dataset']}\")\n",
    "    print(f\"   Source: {row['Source']}\")\n",
    "    print(f\"   Size: {row['Images']} images\")\n",
    "    print(f\"   Classes: {row['Classes']}\")\n",
    "    print(f\"   ‚úÖ Advantages: {row['Advantages']}\")\n",
    "    print(f\"   ‚ö†Ô∏è  Challenges: {row['Challenges']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of dataset comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset sizes for visualization\n",
    "dataset_names = ['Stanford Cars', 'Cars (Kaggle)', 'CompCars', 'VehicleNet']\n",
    "dataset_sizes = [16185, 8144, 136726, 5600000]\n",
    "dataset_classes = [196, 196, 1716, 1000]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot dataset sizes\n",
    "colors = ['skyblue', 'lightgreen', 'orange', 'lightcoral']\n",
    "ax1.bar(dataset_names, dataset_sizes, color=colors, alpha=0.7)\n",
    "ax1.set_title('Dataset Sizes (Number of Images)', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Images')\n",
    "ax1.set_xlabel('Dataset')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(dataset_sizes):\n",
    "    if v >= 1000000:\n",
    "        label = f'{v/1000000:.1f}M'\n",
    "    elif v >= 1000:\n",
    "        label = f'{v/1000:.1f}K'\n",
    "    else:\n",
    "        label = str(v)\n",
    "    ax1.text(i, v + max(dataset_sizes)*0.01, label, ha='center', va='bottom')\n",
    "\n",
    "# Plot number of classes\n",
    "ax2.bar(dataset_names, dataset_classes, color=colors, alpha=0.7)\n",
    "ax2.set_title('Number of Classes', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Number of Classes')\n",
    "ax2.set_xlabel('Dataset')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(dataset_classes):\n",
    "    ax2.text(i, v + max(dataset_classes)*0.01, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ CHOSEN DATASET: Stanford Cars Dataset\")\n",
    "print(\"Reasons:\")\n",
    "print(\"- Good balance of size and manageability\")\n",
    "print(\"- Well-documented and clean\")\n",
    "print(\"- Available on Kaggle\")\n",
    "print(\"- Will be adapted to focus on major brands only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647faedb",
   "metadata": {},
   "source": [
    "## 3. Analyze Data Requirements\n",
    "\n",
    "Let's calculate storage requirements and analyze preprocessing needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate storage and processing requirements\n",
    "\n",
    "class DataRequirementsAnalysis:\n",
    "    def __init__(self):\n",
    "        self.target_image_size = (224, 224, 3)  # RGB\n",
    "        self.num_images_estimated = 8000  # Conservative estimate for our subset\n",
    "        self.train_split = 0.7\n",
    "        self.val_split = 0.15\n",
    "        self.test_split = 0.15\n",
    "        \n",
    "    def calculate_storage_requirements(self):\n",
    "        # Calculate storage needs\n",
    "        pixels_per_image = self.target_image_size[0] * self.target_image_size[1] * self.target_image_size[2]\n",
    "        bytes_per_image_raw = pixels_per_image  # 1 byte per pixel value\n",
    "        bytes_per_image_compressed = bytes_per_image_raw * 0.1  # JPEG compression ~10% of raw\n",
    "        \n",
    "        total_raw_mb = (bytes_per_image_raw * self.num_images_estimated) / (1024 * 1024)\n",
    "        total_compressed_mb = (bytes_per_image_compressed * self.num_images_estimated) / (1024 * 1024)\n",
    "        \n",
    "        print(\"=== STORAGE REQUIREMENTS ===\")\n",
    "        print(f\"Target image size: {self.target_image_size[0]}x{self.target_image_size[1]}x{self.target_image_size[2]}\")\n",
    "        print(f\"Estimated images: {self.num_images_estimated:,}\")\n",
    "        print(f\"Raw storage needed: {total_raw_mb:.1f} MB\")\n",
    "        print(f\"Compressed storage (JPEG): {total_compressed_mb:.1f} MB\")\n",
    "        print(f\"Recommended free space: {total_compressed_mb * 3:.1f} MB (including workspace)\")\n",
    "        print()\n",
    "        \n",
    "    def calculate_data_splits(self):\n",
    "        train_images = int(self.num_images_estimated * self.train_split)\n",
    "        val_images = int(self.num_images_estimated * self.val_split)\n",
    "        test_images = int(self.num_images_estimated * self.test_split)\n",
    "        \n",
    "        print(\"=== DATA SPLIT PLAN ===\")\n",
    "        print(f\"Training set: {train_images:,} images ({self.train_split:.0%})\")\n",
    "        print(f\"Validation set: {val_images:,} images ({self.val_split:.0%})\")\n",
    "        print(f\"Test set: {test_images:,} images ({self.test_split:.0%})\")\n",
    "        print(f\"Total: {train_images + val_images + test_images:,} images\")\n",
    "        print()\n",
    "        \n",
    "    def analyze_preprocessing_needs(self):\n",
    "        print(\"=== PREPROCESSING REQUIREMENTS ===\")\n",
    "        preprocessing_steps = [\n",
    "            \"‚úÖ Image format standardization (convert to RGB)\",\n",
    "            \"‚úÖ Resize to 224x224 pixels (CNN standard)\",\n",
    "            \"‚úÖ Normalize pixel values (0-1 range)\",\n",
    "            \"‚úÖ Data augmentation (rotation, flip, zoom)\",\n",
    "            \"‚úÖ Brand-level grouping (map models to brands)\",\n",
    "            \"‚úÖ Train/validation/test splits\"\n",
    "        ]\n",
    "        \n",
    "        for step in preprocessing_steps:\n",
    "            print(step)\n",
    "        print()\n",
    "        \n",
    "        print(\"Expected preprocessing time: 30-60 minutes\")\n",
    "        print(\"Memory requirements during processing: 2-4 GB RAM\")\n",
    "\n",
    "# Run analysis\n",
    "analysis = DataRequirementsAnalysis()\n",
    "analysis.calculate_storage_requirements()\n",
    "analysis.calculate_data_splits()\n",
    "analysis.analyze_preprocessing_needs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ab9c4",
   "metadata": {},
   "source": [
    "## 4. Set Project Scope and Goals\n",
    "\n",
    "Define specific, measurable objectives for our car brand recognition project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project scope and measurable objectives\n",
    "\n",
    "class ProjectGoals:\n",
    "    def __init__(self):\n",
    "        self.project_timeline = \"4-6 weeks\"\n",
    "        self.minimum_accuracy = 0.70  # 70%\n",
    "        self.target_accuracy = 0.85   # 85%\n",
    "        self.stretch_accuracy = 0.90  # 90%\n",
    "        \n",
    "    def define_scope(self):\n",
    "        print(\"=== PROJECT SCOPE ===\")\n",
    "        scope_items = {\n",
    "            \"IN SCOPE\": [\n",
    "                \"Car brand classification (8 major brands)\",\n",
    "                \"Transfer learning with pre-trained CNN\",\n",
    "                \"Web application for image upload and prediction\",\n",
    "                \"Model evaluation and performance analysis\",\n",
    "                \"Documentation and project report\"\n",
    "            ],\n",
    "            \"OUT OF SCOPE\": [\n",
    "                \"Car model identification (specific models)\",\n",
    "                \"Multiple car detection in single image\",\n",
    "                \"Real-time video processing\",\n",
    "                \"Mobile app development\",\n",
    "                \"Production deployment with scaling\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        for category, items in scope_items.items():\n",
    "            print(f\"\\n{category}:\")\n",
    "            for item in items:\n",
    "                print(f\"  ‚Ä¢ {item}\")\n",
    "        print()\n",
    "        \n",
    "    def define_objectives(self):\n",
    "        print(\"=== SMART OBJECTIVES ===\")\n",
    "        objectives = [\n",
    "            f\"üéØ Achieve minimum {self.minimum_accuracy:.0%} accuracy on test set\",\n",
    "            f\"üéØ Target {self.target_accuracy:.0%} accuracy for production readiness\",\n",
    "            f\"üéØ Complete project within {self.project_timeline}\",\n",
    "            \"üéØ Deploy working web application\",\n",
    "            \"üéØ Document all code and methodology\",\n",
    "            \"üéØ Present results with clear visualizations\"\n",
    "        ]\n",
    "        \n",
    "        for obj in objectives:\n",
    "            print(obj)\n",
    "        print()\n",
    "        \n",
    "    def define_constraints(self):\n",
    "        print(\"=== PROJECT CONSTRAINTS ===\")\n",
    "        constraints = [\n",
    "            \"üíª Hardware: Local machine with limited GPU\",\n",
    "            \"‚è∞ Time: 4-6 weeks development window\",\n",
    "            \"üí∞ Budget: Free datasets and tools only\",\n",
    "            \"üìö Scope: Course assignment requirements\",\n",
    "            \"üîß Technical: Python/TensorFlow ecosystem\"\n",
    "        ]\n",
    "        \n",
    "        for constraint in constraints:\n",
    "            print(constraint)\n",
    "        print()\n",
    "        \n",
    "    def define_deliverables(self):\n",
    "        print(\"=== PROJECT DELIVERABLES ===\")\n",
    "        deliverables = [\n",
    "            \"üìÅ Complete code repository\",\n",
    "            \"ü§ñ Trained model files\",\n",
    "            \"üåê Web application (Streamlit/Gradio)\",\n",
    "            \"üìä Jupyter notebooks with analysis\",\n",
    "            \"üìù Project documentation and report\",\n",
    "            \"üìà Performance evaluation results\",\n",
    "            \"üé• Demo video or screenshots\"\n",
    "        ]\n",
    "        \n",
    "        for deliverable in deliverables:\n",
    "            print(deliverable)\n",
    "\n",
    "# Create and display project goals\n",
    "goals = ProjectGoals()\n",
    "goals.define_scope()\n",
    "goals.define_objectives()\n",
    "goals.define_constraints()\n",
    "goals.define_deliverables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d358ad",
   "metadata": {},
   "source": [
    "## 5. Choose the Machine Learning Approach\n",
    "\n",
    "Compare different ML approaches and select the most suitable one for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c15267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ML approaches for car brand classification\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define different approaches\n",
    "approaches = {\n",
    "    'Approach': [\n",
    "        'Transfer Learning (CNN)',\n",
    "        'Train from Scratch (CNN)', \n",
    "        'Traditional ML (Features)',\n",
    "        'Ensemble Methods'\n",
    "    ],\n",
    "    'Base_Models': [\n",
    "        'MobileNetV2, ResNet50, EfficientNet',\n",
    "        'Custom CNN Architecture',\n",
    "        'SVM, Random Forest',\n",
    "        'Multiple CNN + Voting'\n",
    "    ],\n",
    "    'Training_Time': [\n",
    "        '2-4 hours',\n",
    "        '8-24 hours',\n",
    "        '1-2 hours',\n",
    "        '6-12 hours'\n",
    "    ],\n",
    "    'Expected_Accuracy': [\n",
    "        '80-90%',\n",
    "        '70-85%',\n",
    "        '60-75%',\n",
    "        '85-92%'\n",
    "    ],\n",
    "    'Computational_Requirements': [\n",
    "        'Medium',\n",
    "        'High',\n",
    "        'Low',\n",
    "        'High'\n",
    "    ],\n",
    "    'Implementation_Complexity': [\n",
    "        'Low-Medium',\n",
    "        'High',\n",
    "        'Medium',\n",
    "        'High'\n",
    "    ],\n",
    "    'Advantages': [\n",
    "        'Fast training, proven results',\n",
    "        'Full control, custom features',\n",
    "        'Simple, interpretable',\n",
    "        'Best accuracy potential'\n",
    "    ],\n",
    "    'Disadvantages': [\n",
    "        'Limited customization',\n",
    "        'Long training, risk of overfitting',\n",
    "        'Limited accuracy ceiling',\n",
    "        'Complex implementation'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_approaches = pd.DataFrame(approaches)\n",
    "\n",
    "print(\"=== ML APPROACH COMPARISON ===\\n\")\n",
    "for idx, row in df_approaches.iterrows():\n",
    "    print(f\"üî¨ {row['Approach']}\")\n",
    "    print(f\"   Models: {row['Base_Models']}\")\n",
    "    print(f\"   Training Time: {row['Training_Time']}\")\n",
    "    print(f\"   Expected Accuracy: {row['Expected_Accuracy']}\")\n",
    "    print(f\"   Complexity: {row['Implementation_Complexity']}\")\n",
    "    print(f\"   ‚úÖ Pros: {row['Advantages']}\")\n",
    "    print(f\"   ‚ùå Cons: {row['Disadvantages']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate computational requirements and make decision\n",
    "\n",
    "class ModelComplexityAnalysis:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'MobileNetV2': {\n",
    "                'parameters': '3.4M',\n",
    "                'size_mb': 14,\n",
    "                'inference_speed': 'Fast',\n",
    "                'mobile_friendly': True,\n",
    "                'accuracy_range': '85-89%'\n",
    "            },\n",
    "            'ResNet50': {\n",
    "                'parameters': '25.6M', \n",
    "                'size_mb': 98,\n",
    "                'inference_speed': 'Medium',\n",
    "                'mobile_friendly': False,\n",
    "                'accuracy_range': '87-91%'\n",
    "            },\n",
    "            'EfficientNetB0': {\n",
    "                'parameters': '5.3M',\n",
    "                'size_mb': 21,\n",
    "                'inference_speed': 'Fast',\n",
    "                'mobile_friendly': True,\n",
    "                'accuracy_range': '86-90%'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def compare_models(self):\n",
    "        print(\"=== CNN MODEL COMPARISON ===\\n\")\n",
    "        for model_name, specs in self.models.items():\n",
    "            print(f\"üß† {model_name}\")\n",
    "            print(f\"   Parameters: {specs['parameters']}\")\n",
    "            print(f\"   Model Size: {specs['size_mb']} MB\")\n",
    "            print(f\"   Speed: {specs['inference_speed']}\")\n",
    "            print(f\"   Mobile-friendly: {specs['mobile_friendly']}\")\n",
    "            print(f\"   Expected Accuracy: {specs['accuracy_range']}\")\n",
    "            print()\n",
    "    \n",
    "    def make_recommendation(self):\n",
    "        print(\"=== RECOMMENDED APPROACH ===\")\n",
    "        print(\"üéØ PRIMARY: Transfer Learning with MobileNetV2\")\n",
    "        print(\"Reasons:\")\n",
    "        print(\"  ‚Ä¢ Perfect balance of accuracy and efficiency\")\n",
    "        print(\"  ‚Ä¢ Fast training and inference\")\n",
    "        print(\"  ‚Ä¢ Suitable for deployment\")\n",
    "        print(\"  ‚Ä¢ Well-documented and reliable\")\n",
    "        print()\n",
    "        print(\"üéØ BACKUP: Transfer Learning with EfficientNetB0\")\n",
    "        print(\"Reasons:\")\n",
    "        print(\"  ‚Ä¢ Slightly better accuracy potential\")\n",
    "        print(\"  ‚Ä¢ Still efficient and deployable\")\n",
    "        print(\"  ‚Ä¢ Good alternative if MobileNetV2 underperforms\")\n",
    "\n",
    "analysis = ModelComplexityAnalysis()\n",
    "analysis.compare_models()\n",
    "analysis.make_recommendation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad72a6",
   "metadata": {},
   "source": [
    "## 6. Define Success Metrics\n",
    "\n",
    "Establish evaluation criteria and implement functions to measure model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0647b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics and success criteria\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class ModelEvaluationFramework:\n",
    "    def __init__(self):\n",
    "        self.target_metrics = {\n",
    "            'accuracy': {'minimum': 0.70, 'target': 0.85, 'excellent': 0.90},\n",
    "            'precision': {'minimum': 0.65, 'target': 0.80, 'excellent': 0.85},\n",
    "            'recall': {'minimum': 0.65, 'target': 0.80, 'excellent': 0.85},\n",
    "            'f1_score': {'minimum': 0.65, 'target': 0.80, 'excellent': 0.85}\n",
    "        }\n",
    "    \n",
    "    def define_metrics(self):\n",
    "        print(\"=== SUCCESS METRICS DEFINITION ===\\n\")\n",
    "        \n",
    "        print(\"üìä PRIMARY METRICS:\")\n",
    "        print(\"  ‚Ä¢ Accuracy: Overall correct predictions / total predictions\")\n",
    "        print(\"  ‚Ä¢ Precision: True positives / (true positives + false positives)\")\n",
    "        print(\"  ‚Ä¢ Recall: True positives / (true positives + false negatives)\")\n",
    "        print(\"  ‚Ä¢ F1-Score: Harmonic mean of precision and recall\")\n",
    "        print()\n",
    "        \n",
    "        print(\"üìà SECONDARY METRICS:\")\n",
    "        print(\"  ‚Ä¢ Training time efficiency\")\n",
    "        print(\"  ‚Ä¢ Inference speed (predictions per second)\")\n",
    "        print(\"  ‚Ä¢ Model size (MB)\")\n",
    "        print(\"  ‚Ä¢ Training stability (convergence)\")\n",
    "        print()\n",
    "        \n",
    "        print(\"üéØ SUCCESS THRESHOLDS:\")\n",
    "        for metric, thresholds in self.target_metrics.items():\n",
    "            print(f\"  {metric.capitalize()}:\")\n",
    "            print(f\"    Minimum (Pass): {thresholds['minimum']:.1%}\")\n",
    "            print(f\"    Target (Good): {thresholds['target']:.1%}\")\n",
    "            print(f\"    Excellent: {thresholds['excellent']:.1%}\")\n",
    "        print()\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred, class_names):\n",
    "        \"\"\"\n",
    "        Calculate comprehensive evaluation metrics.\n",
    "        \n",
    "        Args:\n",
    "            y_true: True labels\n",
    "            y_pred: Predicted labels  \n",
    "            class_names: List of class names\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of metric scores\n",
    "        \"\"\"\n",
    "        # Calculate basic metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='weighted'\n",
    "        )\n",
    "        \n",
    "        # Calculate per-class metrics\n",
    "        precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=None, labels=range(len(class_names))\n",
    "        )\n",
    "        \n",
    "        metrics = {\n",
    "            'overall': {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1\n",
    "            },\n",
    "            'per_class': {\n",
    "                'precision': dict(zip(class_names, precision_per_class)),\n",
    "                'recall': dict(zip(class_names, recall_per_class)),\n",
    "                'f1_score': dict(zip(class_names, f1_per_class))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def evaluate_performance_level(self, metrics):\n",
    "        \"\"\"Evaluate if model meets success criteria.\"\"\"\n",
    "        overall = metrics['overall']\n",
    "        \n",
    "        performance_levels = []\n",
    "        for metric_name, score in overall.items():\n",
    "            thresholds = self.target_metrics[metric_name]\n",
    "            \n",
    "            if score >= thresholds['excellent']:\n",
    "                level = 'Excellent'\n",
    "            elif score >= thresholds['target']:\n",
    "                level = 'Good'\n",
    "            elif score >= thresholds['minimum']:\n",
    "                level = 'Acceptable'\n",
    "            else:\n",
    "                level = 'Needs Improvement'\n",
    "            \n",
    "            performance_levels.append((metric_name, score, level))\n",
    "        \n",
    "        return performance_levels\n",
    "    \n",
    "    def visualize_confusion_matrix(self, y_true, y_pred, class_names):\n",
    "        \"\"\"Create confusion matrix visualization.\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title('Confusion Matrix - Car Brand Classification')\n",
    "        plt.xlabel('Predicted Brand')\n",
    "        plt.ylabel('True Brand')\n",
    "        plt.tight_layout()\n",
    "        return plt.gcf()\n",
    "\n",
    "# Initialize evaluation framework\n",
    "evaluator = ModelEvaluationFramework()\n",
    "evaluator.define_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d224624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Simulate model evaluation with sample data\n",
    "\n",
    "# Simulate some results for demonstration\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "n_classes = 8\n",
    "class_names = ['Audi', 'BMW', 'Ford', 'Honda', 'Mercedes', 'Nissan', 'Tesla', 'Toyota']\n",
    "\n",
    "# Simulate predictions (assuming a reasonably good model)\n",
    "y_true = np.random.randint(0, n_classes, n_samples)\n",
    "# Add some realistic prediction accuracy (~80%)\n",
    "y_pred = y_true.copy()\n",
    "# Introduce some errors\n",
    "error_indices = np.random.choice(n_samples, size=int(n_samples * 0.2), replace=False)\n",
    "y_pred[error_indices] = np.random.randint(0, n_classes, len(error_indices))\n",
    "\n",
    "print(\"=== SAMPLE EVALUATION RESULTS ===\\n\")\n",
    "\n",
    "# Calculate metrics\n",
    "sample_metrics = evaluator.calculate_metrics(y_true, y_pred, class_names)\n",
    "\n",
    "print(\"üìä OVERALL PERFORMANCE:\")\n",
    "for metric, score in sample_metrics['overall'].items():\n",
    "    print(f\"  {metric.capitalize()}: {score:.3f} ({score:.1%})\")\n",
    "print()\n",
    "\n",
    "# Evaluate performance level\n",
    "performance_levels = evaluator.evaluate_performance_level(sample_metrics)\n",
    "print(\"üéØ PERFORMANCE ASSESSMENT:\")\n",
    "for metric_name, score, level in performance_levels:\n",
    "    print(f\"  {metric_name.capitalize()}: {level} ({score:.1%})\")\n",
    "print()\n",
    "\n",
    "# Show per-class F1 scores\n",
    "print(\"üè∑Ô∏è  PER-CLASS F1 SCORES:\")\n",
    "for brand, f1_score in sample_metrics['per_class']['f1_score'].items():\n",
    "    print(f\"  {brand}: {f1_score:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ Problem understanding phase complete!\")\n",
    "print(\"Next steps:\")\n",
    "print(\"  1. Download and prepare dataset\")\n",
    "print(\"  2. Implement data preprocessing pipeline\")\n",
    "print(\"  3. Build and train the model\")\n",
    "print(\"  4. Evaluate performance using these metrics\")\n",
    "print(\"  5. Deploy web application\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
